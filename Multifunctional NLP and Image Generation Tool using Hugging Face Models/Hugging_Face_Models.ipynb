{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR2Fxaf5Uom3"
   },
   "source": [
    "**Problem Statement**\n",
    "\n",
    "The project emphasises on creating a multifunctional tool that enables users to select and utilize different pre-trained from Hugging Face for tasks like text summarization, next word prediction, story prediction, chatbot, sentiment analysis, question answering, and image generation. A front end would be implemented which allows the user to select the task and input the required text or image for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Np5kRbLtoo92",
    "outputId": "0a2cc1e3-7ae2-40c6-b2ce-989e5dd33efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (0.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-kWGYEoo85U",
    "outputId": "577bd96f-6340-4e94-93a6-0c3287072e22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (3.16.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp38-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.1/10.0 MB 10.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.7/10.0 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.0/10.0 MB 9.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.4/10.0 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading regex-2024.11.6-cp38-cp38-win_amd64.whl (274 kB)\n",
      "Downloading safetensors-0.4.5-cp38-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.20.3-cp38-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 9.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 tqdm-4.67.0 transformers-4.46.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\SAROBIN SILVIYA\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\SAROBIN SILVIYA\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\SAROBIN SILVIYA\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "# Transformers architecture to perform NLP tasks\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ekTtk4lOXurd",
    "outputId": "b732fe26-28a7-4e5e-b1e9-9ec33c418964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting diffusers\n",
      "  Downloading diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (0.26.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (0.4.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from diffusers) (10.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub>=0.23.2->diffusers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub>=0.23.2->diffusers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub>=0.23.2->diffusers) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from importlib-metadata->diffusers) (3.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->diffusers) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->diffusers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from requests->diffusers) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarobin silviya\\appdata\\roaming\\python\\python38\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.2->diffusers) (0.4.6)\n",
      "Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.6/2.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 8.0 MB/s eta 0:00:00\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "  WARNING: The script diffusers-cli.exe is installed in 'C:\\Users\\SAROBIN SILVIYA\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V35p71KTX-Z4",
    "outputId": "d380cb3e-00ee-44a4-8062-8a6d61797814",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnRBgB8ZU5Z7",
    "outputId": "5256961d-1136-46e6-a204-110d718723b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Hugging_face.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Hugging_face.py\n",
    "# Import necessary packages\n",
    "import torch\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import streamlit as st\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Checking for CUDA availability and suggesting accelerate library\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if not torch.cuda.is_available():\n",
    "    st.warning(\"CUDA not available, running on CPU. Consider installing `accelerate` for optimized performance on CPU:\\n`pip install accelerate`\")\n",
    "\n",
    "# Streamlit App Title and Description\n",
    "st.title('üåü Multifunctional NLP and Image Generation Tool using Hugging Face Models')\n",
    "st.write('''\n",
    "    This app provides various AI-powered functionalities, including text summarization, \n",
    "    next-word prediction, story generation, chatbot interaction, sentiment analysis, \n",
    "    question answering, and image generation.\n",
    "''')\n",
    "\n",
    "# Sidebar for task selection\n",
    "task = st.sidebar.selectbox('Choose a task', [\n",
    "    'Text Summarization', 'Next Word Prediction', 'Story Prediction', \n",
    "    'Chatbot', 'Sentiment Analysis', 'Question Answering', 'Image Generation'\n",
    "])\n",
    "\n",
    "# Function for text summarization\n",
    "if task == 'Text Summarization':\n",
    "    st.subheader('üìù Text Summarization')\n",
    "    user_input = st.text_area('Enter text to summarize:')\n",
    "    if st.button('Summarize'):\n",
    "        with st.spinner(\"Generating summary...\"):\n",
    "            model_name = \"facebook/bart-large-cnn\"\n",
    "            tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "            model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "            \n",
    "            def summarize(text, model, tokenizer):\n",
    "                inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "                summary_ids = model.generate(inputs, max_length=200, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "                return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            summary = summarize(user_input, model, tokenizer)\n",
    "            st.write(\"### Summary\")\n",
    "            st.write(summary)\n",
    "\n",
    "# Function for next word prediction\n",
    "elif task == 'Next Word Prediction':\n",
    "    st.subheader('üîÆ Next Word Prediction')\n",
    "    user_input = st.text_area('Enter text for prediction:')\n",
    "    if st.button('Predict'):\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n",
    "        \n",
    "        def predict_next_word(prompt, model, tokenizer, top_k=5):\n",
    "            inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "            outputs = model(**inputs)\n",
    "            next_token_logits = outputs.logits[:, -1, :]\n",
    "            top_k_tokens = torch.topk(next_token_logits, top_k).indices[0].tolist()\n",
    "            return [tokenizer.decode([token]) for token in top_k_tokens]\n",
    "        \n",
    "        predicted_words = predict_next_word(user_input, model, tokenizer)\n",
    "        st.write(\"### Next Word Predictions\")\n",
    "        st.write(predicted_words)\n",
    "\n",
    "# Function for story prediction\n",
    "elif task == 'Story Prediction':\n",
    "    st.subheader('üìñ Story Prediction')\n",
    "    user_input = st.text_area('Enter text to continue the story:')\n",
    "    if st.button('Generate'):\n",
    "        with st.spinner(\"Generating story...\"):\n",
    "            story_predictor = pipeline('text-generation', model='gpt2')\n",
    "            story = story_predictor(user_input, max_length=200, clean_up_tokenization_spaces=True)[0]['generated_text']\n",
    "            st.write(\"### Generated Story\")\n",
    "            st.write(story)\n",
    "\n",
    "# Function for chatbot interaction\n",
    "elif task == 'Chatbot':\n",
    "    st.subheader('ü§ñ Chatbot')\n",
    "    model_name = \"microsoft/DialoGPT-medium\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side='left')\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "    chat_history_ids = None\n",
    "    user_input = st.text_input(\"You:\")\n",
    "    if st.button('Chat'):\n",
    "        if user_input.lower() != 'quit':\n",
    "            new_user_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt').to(device)\n",
    "            bot_input_ids = torch.cat([chat_history_ids, new_user_input_ids], dim=-1) if chat_history_ids is not None else new_user_input_ids\n",
    "            chat_history_ids = model.generate(bot_input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n",
    "            response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
    "            st.write(\"Bot:\", response)\n",
    "\n",
    "# Function for sentiment analysis\n",
    "elif task == 'Sentiment Analysis':\n",
    "    st.subheader('üòä Sentiment Analysis')\n",
    "    user_input = st.text_area('Enter text for sentiment analysis:')\n",
    "    if st.button('Analyze'):\n",
    "        sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "        results = sentiment_analysis(re.split(r'([.!?])', user_input))\n",
    "        for result in results:\n",
    "            st.write(f\"Sentiment: {result['label']}, Score: {result['score']:.4f}\")\n",
    "\n",
    "# Function for question answering\n",
    "elif task == 'Question Answering':\n",
    "    st.subheader('‚ùì Question Answering')\n",
    "    context = st.text_area('Enter context text:')\n",
    "    question = st.text_input('Enter question:')\n",
    "    if st.button('Answer'):\n",
    "        with st.spinner(\"Finding answer...\"):\n",
    "            model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForQuestionAnswering.from_pretrained(model_name).to(device)\n",
    "            \n",
    "            inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\").to(device)\n",
    "            answer_start_scores, answer_end_scores = model(**inputs).start_logits, model(**inputs).end_logits\n",
    "            answer = tokenizer.convert_tokens_to_string(\n",
    "                tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].tolist()[0][torch.argmax(answer_start_scores):torch.argmax(answer_end_scores) + 1])\n",
    "            )\n",
    "            st.write(\"Answer:\", answer)\n",
    "\n",
    "# Function for image generation\n",
    "elif task == 'Image Generation':\n",
    "    st.subheader('üñºÔ∏è Image Generation')\n",
    "    user_input = st.text_area('Enter prompt for image generation:')\n",
    "    if st.button('Generate Image'):\n",
    "        with st.spinner(\"Generating image...\"):\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
    "            image = pipe(user_input).images[0]\n",
    "            st.image(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v70Nv9wcxjaz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
